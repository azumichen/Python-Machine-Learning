{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20Mn data MovieLens Experiment\n",
    "\n",
    "The original embedding+collaborative filtering + nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[task:experiment with CR on movielens 20m data to cross check the result against new technique>>start]<2018-10-23_15:03:59|0s,0s>\t\n"
     ]
    }
   ],
   "source": [
    "from ray.lprint import lprint\n",
    "l = lprint(\"experiment with CR on movielens 20m data to cross check the result against new technique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[has GPU cuda]<2018-10-23_15:03:00|0s,0s>\tTrue\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "SEQ_LEN = 19\n",
    "DIM = 100\n",
    "l.p(\"has GPU cuda\",CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/data/ml-20m/ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loading csv file]<2018-10-23_15:03:01|1s,1s>\t/data/ml-20m/ratings.csv\n",
      "[csv file loaded]<2018-10-23_15:03:09|8s,9s>\t\n"
     ]
    }
   ],
   "source": [
    "l.p(\"loading csv file\", DATA)\n",
    "rate_df = pd.read_csv(DATA)\n",
    "l.p(\"csv file loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users and movies:\t 138493 \t 26744\n"
     ]
    }
   ],
   "source": [
    "userId = list(set(rate_df[\"userId\"]))\n",
    "movieId = list(set(rate_df[\"movieId\"]))\n",
    "print(\"total number of users and movies:\\t\",len(userId),\"\\t\",len(movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[making dictionary]<2018-10-23_15:03:12|2s,12s>\t\n"
     ]
    }
   ],
   "source": [
    "l.p(\"making dictionary\")\n",
    "u2i = dict((v,k) for k,v in enumerate(userId))\n",
    "m2i = dict((v,k) for k,v in enumerate(movieId))\n",
    "i2u = dict((k,v) for k,v in enumerate(userId))\n",
    "i2m = dict((k,v) for k,v in enumerate(movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df[\"movieIdx\"] = rate_df.movieId.apply(lambda x:m2i[x]).astype(int)\n",
    "rate_df[\"userIdx\"] = rate_df.userId.apply(lambda x:u2i[x]).astype(int)\n",
    "rate_df[\"rating\"] = rate_df[\"rating\"]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from ray.matchbox import Trainer,Arr_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl = DataLoader(train_ds,batch_size=1, shuffle = True)\n",
    "# print(len(dl))\n",
    "# gen = iter(dl)\n",
    "# next(gen)[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cf_nn(nn.Module):\n",
    "    def __init__(self, hidden_size,user_size,item_size):\n",
    "        \"\"\"\n",
    "        Collaborative Filtering with Neural Network\n",
    "        \"\"\"\n",
    "        super(cf_nn,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.user_size = user_size\n",
    "        self.item_size = item_size\n",
    "        self.emb_u = nn.Embedding(self.user_size,self.hidden_size,)\n",
    "        self.emb_v = nn.Embedding(self.item_size,self.hidden_size,)\n",
    "        \n",
    "        self.mlp = nn.Sequential(*[\n",
    "            nn.Dropout(.3),\n",
    "            nn.Linear(hidden_size*2, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256,1,bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        ])\n",
    "    \n",
    "    def forward(self,u_idx,v_idx):\n",
    "        cated = torch.cat([self.emb_u(u_idx.long().squeeze(0)),\n",
    "                             self.emb_v(v_idx.long().squeeze(0))], dim=1)\n",
    "        return self.mlp(cated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def action(*args,**kwargs):\n",
    "    # get data from data feeder\n",
    "    v_idx,u_idx,y = args[0]\n",
    "    if CUDA:\n",
    "        v_idx,u_idx,y = v_idx.cuda(),u_idx.cuda(),y.cuda().permute(1,0)\n",
    "    y = y.float()\n",
    "    \n",
    "    # Clear the Jacobian Matrix\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # Predict y hat\n",
    "    y_ = cf_model(u_idx, v_idx)\n",
    "    # Calculate Loss\n",
    "    loss = loss_func(y_,y)\n",
    "    \n",
    "    # Backward Propagation\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    # Mean Absolute Loss as print out metrics\n",
    "    mae = torch.mean(torch.abs(y_-y))\n",
    "    return {\"loss\":loss.item(),\"mae\":mae.item()}\n",
    "\n",
    "def val_action(*args,**kwargs):\n",
    "    \"\"\"\n",
    "    A validation step\n",
    "    Exactly the same like train step, but no learning, only forward pass\n",
    "    \"\"\"\n",
    "    v_idx,u_idx,y = args[0]\n",
    "    if CUDA:\n",
    "        v_idx,u_idx,y = v_idx.cuda(),u_idx.cuda(),y.cuda().permute(1,0)\n",
    "    y = y.float()\n",
    "    \n",
    "    y_ = cf_model(u_idx, v_idx)\n",
    "    \n",
    "    loss = loss_func(y_,y)\n",
    "    mae = torch.mean(torch.abs(y_-y))\n",
    "    return {\"loss\":loss.item(),\"mae\":mae.item()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training fold number]<2018-10-23_15:03:10|30s,70s>\t0\n",
      "[making train/test split]<2018-10-23_15:03:10|0s,70s>\t\n",
      "[generating pytorch dataset]<2018-10-23_15:03:14|4s,74s>\t\n",
      "[creating model]<2018-10-23_15:03:14|0s,74s>\t\n",
      "[loading model to GPU]<2018-10-23_15:03:15|0s,75s>\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚≠ê[ep_0_i_9]\tloss\t0.079‚ú®\tmae\t0.239:   0%|          | 6/2446 [00:00<00:42, 56.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_len]<2018-10-23_15:03:17|2s,77s>\t2446\n",
      "[valid_len]<2018-10-23_15:03:17|0s,77s>\t2438\n",
      "[start training]<2018-10-23_15:03:17|0s,77s>\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚≠ê[ep_0_i_2444]\tloss\t0.031‚ú®\tmae\t0.136: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2446/2446 [00:38<00:00, 64.25it/s]\n",
      "üòé[val_ep_0_i_2437]\tloss\t0.037üòÇ\tmae\t0.150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2438/2438 [00:34<00:00, 70.97it/s]\n",
      "‚≠ê[ep_1_i_2444]\tloss\t0.032‚ú®\tmae\t0.140: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2446/2446 [00:38<00:00, 64.31it/s]\n",
      "üòé[val_ep_1_i_2437]\tloss\t0.036üòÇ\tmae\t0.149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2438/2438 [00:34<00:00, 70.91it/s]\n",
      "‚≠ê[ep_2_i_2444]\tloss\t0.038‚ú®\tmae\t0.155: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2446/2446 [00:38<00:00, 64.30it/s]\n",
      "üòé[val_ep_2_i_2437]\tloss\t0.037üòÇ\tmae\t0.150: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2438/2438 [00:34<00:00, 70.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training finished]<2018-10-23_15:03:55|217s,295s>\t\n",
      "[Training fold number]<2018-10-23_15:03:55|0s,295s>\t1\n",
      "[making train/test split]<2018-10-23_15:03:55|0s,295s>\t\n",
      "[generating pytorch dataset]<2018-10-23_15:03:59|3s,299s>\t\n",
      "[creating model]<2018-10-23_15:03:59|0s,299s>\t\n",
      "[loading model to GPU]<2018-10-23_15:03:59|0s,299s>\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚≠ê[ep_0_i_9]\tloss\t0.089‚ú®\tmae\t0.255:   0%|          | 7/2438 [00:00<00:38, 62.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_len]<2018-10-23_15:03:59|0s,299s>\t2438\n",
      "[valid_len]<2018-10-23_15:03:59|0s,299s>\t2446\n",
      "[start training]<2018-10-23_15:03:59|0s,299s>\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚≠ê[ep_0_i_2434]\tloss\t0.034‚ú®\tmae\t0.145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2438/2438 [00:37<00:00, 64.47it/s]\n",
      "üòé[val_ep_0_i_2445]\tloss\t0.037üòÇ\tmae\t0.149: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2446/2446 [00:34<00:00, 70.87it/s]\n",
      "‚≠ê[ep_1_i_2434]\tloss\t0.029‚ú®\tmae\t0.133: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2438/2438 [00:37<00:00, 64.55it/s]\n",
      "üòé[val_ep_1_i_2445]\tloss\t0.036üòÇ\tmae\t0.148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2446/2446 [00:34<00:00, 70.31it/s]\n",
      "‚≠ê[ep_2_i_2434]\tloss\t0.032‚ú®\tmae\t0.138: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2438/2438 [00:37<00:00, 64.47it/s]\n",
      "üòé[val_ep_2_i_2445]\tloss\t0.036üòÇ\tmae\t0.148: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2446/2446 [00:35<00:00, 35.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training finished]<2018-10-23_15:03:37|218s,517s>\t\n"
     ]
    }
   ],
   "source": [
    "K = 2 # two fold validation\n",
    "BS = 4096\n",
    "user_count = len(userId)\n",
    "random = np.random.rand(user_count)\n",
    "\n",
    "for fold in range(K):\n",
    "    l.p(\"Training fold number\",fold)\n",
    "    l.p(\"making train/test split\")\n",
    "    valid_split = ((fold/K) < random)*(random <= ((fold+1)/K))\n",
    "    train_idx = np.array(range(user_count))[~valid_split]\n",
    "    valid_idx = np.array(range(user_count))[valid_split]\n",
    "\n",
    "    train_df = rate_df[rate_df.userId.isin(train_idx)]\n",
    "    valid_df = rate_df[rate_df.userId.isin(valid_idx)]\n",
    "    \n",
    "    l.p(\"generating pytorch dataset\")\n",
    "    train_ds = Arr_Dataset(\n",
    "        train_df.movieIdx.values,\n",
    "        train_df.userIdx.values,\n",
    "        train_df.rating.values,\n",
    "        bs = BS,\n",
    "                      )\n",
    "    valid_ds = Arr_Dataset(\n",
    "        valid_df.movieIdx.values,\n",
    "        valid_df.userIdx.values,\n",
    "        valid_df.rating.values,\n",
    "        bs = BS,\n",
    "                      )\n",
    "    \n",
    "    # Model\n",
    "    l.p(\"creating model\")\n",
    "    cf_model = cf_nn(hidden_size = DIM, user_size = len(userId),\n",
    "               item_size = len(movieId))\n",
    "    if CUDA:\n",
    "        l.p(\"loading model to GPU\")\n",
    "        torch.cuda.empty_cache()\n",
    "        cf_model.cuda()\n",
    "    opt = Adam(cf_model.parameters())\n",
    "    loss_func = nn.MSELoss()\n",
    "    \n",
    "    trainer = Trainer(train_ds, val_dataset=valid_ds, batch_size=1, print_on=5)\n",
    "    \n",
    "    train_len = len(trainer.train_data)\n",
    "    valid_len = len(trainer.val_data)\n",
    "    \n",
    "    l.p(\"train_len\",train_len)\n",
    "    l.p(\"valid_len\",valid_len)\n",
    "    trainer.action  = action # assiging step function\n",
    "    trainer.val_action  = val_action # assigning validate step function\n",
    "    l.p(\"start training\")\n",
    "    trainer.train(3) # Train for 3 epochs\n",
    "    l.p(\"training finished\")\n",
    "    torch.save(cf_model.state_dict(),\"/data/cf_triditional_fold%s_0.0.1.npy\"%(fold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
