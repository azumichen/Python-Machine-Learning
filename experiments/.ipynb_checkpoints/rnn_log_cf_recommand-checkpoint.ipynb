{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing User Latent Vector With Behavioural Sequence RNN Output For CF Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the situations that we * don't have fresh user embedding* \n",
    "\n",
    "#### Good side of user embedding\n",
    "The latent space empowers the model to featurize the characters of user, entirely by learning.\n",
    "#### Bad side of user embedding\n",
    "Major problems of user embedding is always around the new user:\n",
    "\n",
    "* We train a model with [latent cf + neural network](3.1.3_recommender_system.ipynb)\n",
    "* Usually we won't retrain a model within the same day.\n",
    "* If the new user some with his/her preference record, we have to train it in a way within the consistency of the old user's latent vector\n",
    "* So we can't really apply the adavanced model to the fresh users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the movielens data (yeah, I known, again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /data\n",
    "# !!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# !!unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt   links.csv    movies.csv   ratings.csv  tags.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls /data/ml-latest-small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/data/ml-latest-small/\"\n",
    "DIM = 100 # dimension for embedding\n",
    "SEQ_LEN = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['links.csv', 'tags.csv', 'ratings.csv', 'README.txt', 'movies.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(DATA)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "for f in files:\n",
    "    if f[-3:]==\"csv\":\n",
    "        data[f.split(\".\")[0]] = pd.read_csv(DATA+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'links'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>7020</td>\n",
       "      <td>102721</td>\n",
       "      <td>14904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>5410</td>\n",
       "      <td>67756</td>\n",
       "      <td>811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>77846</td>\n",
       "      <td>118528</td>\n",
       "      <td>12219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>74630</td>\n",
       "      <td>52427</td>\n",
       "      <td>56931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>3391</td>\n",
       "      <td>94321</td>\n",
       "      <td>26827.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId  imdbId   tmdbId\n",
       "4938     7020  102721  14904.0\n",
       "4119     5410   67756    811.0\n",
       "7533    77846  118528  12219.0\n",
       "7468    74630   52427  56931.0\n",
       "2704     3391   94321  26827.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tags'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>364</td>\n",
       "      <td>64957</td>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>1444531041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>547</td>\n",
       "      <td>118880</td>\n",
       "      <td>toplist14</td>\n",
       "      <td>1449757002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>547</td>\n",
       "      <td>134859</td>\n",
       "      <td>toplist15</td>\n",
       "      <td>1449755731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>547</td>\n",
       "      <td>6515</td>\n",
       "      <td>tcm</td>\n",
       "      <td>1190475823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>547</td>\n",
       "      <td>112070</td>\n",
       "      <td>tivo</td>\n",
       "      <td>1476113970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId        tag   timestamp\n",
       "466      364    64957  Brad Pitt  1444531041\n",
       "1219     547   118880  toplist14  1449757002\n",
       "1244     547   134859  toplist15  1449755731\n",
       "954      547     6515        tcm  1190475823\n",
       "1193     547   112070       tivo  1476113970"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ratings'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68468</th>\n",
       "      <td>475</td>\n",
       "      <td>45666</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1447327976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96315</th>\n",
       "      <td>642</td>\n",
       "      <td>1601</td>\n",
       "      <td>4.0</td>\n",
       "      <td>881526098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91484</th>\n",
       "      <td>607</td>\n",
       "      <td>1089</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1118247427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87313</th>\n",
       "      <td>580</td>\n",
       "      <td>51255</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1199493081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70822</th>\n",
       "      <td>494</td>\n",
       "      <td>34405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1342746088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "68468     475    45666     4.0  1447327976\n",
       "96315     642     1601     4.0   881526098\n",
       "91484     607     1089     4.5  1118247427\n",
       "87313     580    51255     4.0  1199493081\n",
       "70822     494    34405     4.0  1342746088"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'movies'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1596</td>\n",
       "      <td>Career Girls (1997)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1732</td>\n",
       "      <td>Big Lebowski, The (1998)</td>\n",
       "      <td>Comedy|Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>3822</td>\n",
       "      <td>Girl on the Bridge, The (Fille sur le pont, La...</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>4723</td>\n",
       "      <td>Deep End, The (2001)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5811</th>\n",
       "      <td>26501</td>\n",
       "      <td>Choose Me (1984)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                              title  \\\n",
       "1268     1596                                Career Girls (1997)   \n",
       "1367     1732                           Big Lebowski, The (1998)   \n",
       "3055     3822  Girl on the Bridge, The (Fille sur le pont, La...   \n",
       "3703     4723                               Deep End, The (2001)   \n",
       "5811    26501                                   Choose Me (1984)   \n",
       "\n",
       "              genres  \n",
       "1268           Drama  \n",
       "1367    Comedy|Crime  \n",
       "3055   Drama|Romance  \n",
       "3703           Drama  \n",
       "5811  Comedy|Romance  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "list(display(k,v.sample(5)) for k,v in data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_df = data[\"ratings\"]\n",
    "len(rate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users and movies:\t 671 \t 9066\n"
     ]
    }
   ],
   "source": [
    "userId = list(set(data[\"ratings\"][\"userId\"]))\n",
    "movieId = list(set(data[\"ratings\"][\"movieId\"]))\n",
    "print(\"total number of users and movies:\\t\",len(userId),\"\\t\",len(movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2i = dict((v,k) for k,v in enumerate(userId))\n",
    "m2i = dict((v,k) for k,v in enumerate(movieId))\n",
    "i2u = dict((k,v) for k,v in enumerate(userId))\n",
    "i2m = dict((k,v) for k,v in enumerate(movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df[\"movieIdx\"] = rate_df.movieId.apply(lambda x:m2i[x]).astype(int)\n",
    "rate_df[\"userIdx\"] = rate_df.userId.apply(lambda x:u2i[x]).astype(int)\n",
    "rate_df[\"rating\"] = rate_df[\"rating\"]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "user_count = len(userId)\n",
    "print(user_count)\n",
    "valid_split = np.random.rand(user_count)>.9\n",
    "train_idx = np.array(range(user_count))[~valid_split]\n",
    "valid_idx = np.array(range(user_count))[valid_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = rate_df[rate_df.userId.isin(train_idx)]\n",
    "valid_df = rate_df[rate_df.userId.isin(valid_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since user id mapping doesn't matter any more. \n",
    "\n",
    "It's easier to make a dataset with contineous user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salvor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/salvor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_u2i = dict((v,k) for k,v in enumerate(set(train_df.userId)))\n",
    "valid_u2i = dict((v,k) for k,v in enumerate(set(valid_df.userId)))\n",
    "train_df[\"userId\"] = train_df.userId.apply(lambda x:train_u2i[x])\n",
    "valid_df[\"userId\"] = valid_df.userId.apply(lambda x:valid_u2i[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_trail(rate_df):\n",
    "    return rate_df.sort_values(by=[\"userId\",\"timestamp\"]).groupby(\"userId\")\n",
    "    #gb.apply(lambda x:x.sample(n = 20, replace = False))\n",
    "gb = get_user_trail(rate_df)\n",
    "train_gb = get_user_trail(train_df)\n",
    "valid_gb = get_user_trail(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gb.apply(lambda x:x.sample(n = 20, replace = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_k = np.array([0]*19 +[1])==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_split(x):\n",
    "    sampled = x.sample(n = 20, replace = False)\n",
    "    seq = sampled.head(19).sort_values(by=\"timestamp\")\n",
    "    y = sampled[pick_k]\n",
    "    return pd.concat([seq,y])\n",
    "\n",
    "class rnn_record(Dataset):\n",
    "    def __init__(self, gb):\n",
    "        self.gb = gb\n",
    "        self.make_seq()\n",
    "    \n",
    "    def make_seq(self):\n",
    "        self.all_seq = self.gb.apply(sample_split)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.gb)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        df = self.all_seq.loc[idx]\n",
    "        seq = df.head(19)[[\"movieIdx\",\"rating\"]].values\n",
    "        targ = df[pick_k][[\"movieIdx\",\"rating\"]].values\n",
    "        targ_v, targ_y =targ[:,0], targ[:,1]\n",
    "        return idx,seq,targ_v,targ_y\n",
    "ds = rnn_record(gb)\n",
    "train_ds = rnn_record(train_gb)\n",
    "valid_ds = rnn_record(valid_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl = DataLoader(ds,batch_size=32,shuffle=True)\n",
    "# gen = iter(dl)\n",
    "\n",
    "# idx,seq,targ_v,targ_y = next(gen)\n",
    "\n",
    "# idx.size(),seq.size(),targ_v.size(),targ_y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mLinkNet(nn.Module):\n",
    "    def __init__(self, hidden_size,v_size):\n",
    "        \"\"\"\n",
    "        mLinkNet, short for missing link net\n",
    "        \"\"\"\n",
    "        super(mLinkNet,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.v_size = v_size\n",
    "        self.emb = nn.Embedding(v_size,hidden_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size = self.hidden_size+1,\n",
    "                          hidden_size= hidden_size+1,\n",
    "                          num_layers=1,\n",
    "                          batch_first = True,\n",
    "                          dropout=0)\n",
    "        \n",
    "        self.mlp = nn.Sequential(*[\n",
    "            nn.Dropout(.3),\n",
    "            nn.Linear(hidden_size*2 + 1, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256,1,bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        ])\n",
    "    \n",
    "    def forward(self,seq,targ_v):\n",
    "        seq_vec = torch.cat([self.emb(seq[:,0].long()),\n",
    "                             seq[:,1].unsqueeze(-1).float()], dim=2)\n",
    "        output, hn = self.rnn(seq_vec)\n",
    "        x = torch.cat([hn.squeeze(0),self.emb(targ_v.long()).squeeze(1)],dim=1)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mln = mLinkNet(hidden_size = DIM, v_size = len(movieId))\n",
    "\n",
    "# mln(seq, targ_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from ray.matchbox import Trainer\n",
    "opt = Adam(mln.parameters())\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(train_ds, val_dataset=valid_ds, batch_size=16, print_on=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(trainer.train_data)\n",
    "valid_len = len(trainer.val_data)\n",
    "def action(*args,**kwargs):\n",
    "    # get data from data feeder\n",
    "    idx,seq,targ_v,y = args[0]\n",
    "    y = y.float()\n",
    "    \n",
    "    # Clear the Jacobian Matrix\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # Predict y hat\n",
    "    y_ = mln(seq, targ_v)\n",
    "    # Calculate Loss\n",
    "    loss = loss_func(y_,y)\n",
    "    \n",
    "    # Backward Propagation\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    # Mean Absolute Loss as print out metrics\n",
    "    mae = torch.mean(torch.abs(y_-y))\n",
    "    if kwargs[\"ite\"] == train_len - 1: # resample the sequence\n",
    "        trainer.train_data.dataset.make_seq()\n",
    "    return {\"loss\":loss.item(),\"mae\":mae.item()}\n",
    "\n",
    "def val_action(*args,**kwargs):\n",
    "    \"\"\"\n",
    "    A validation step\n",
    "    Exactly the same like train step, but no learning, only forward pass\n",
    "    \"\"\"\n",
    "    idx,seq,targ_v,y = args[0]\n",
    "    y = y.float()\n",
    "    \n",
    "    y_ = mln(seq, targ_v)\n",
    "    \n",
    "    loss = loss_func(y_,y)\n",
    "    mae = torch.mean(torch.abs(y_-y))\n",
    "    if kwargs[\"ite\"] == valid_len - 1:\n",
    "        trainer.val_data.dataset.make_seq()\n",
    "    return {\"loss\":loss.item(),\"mae\":mae.item()}\n",
    "trainer.action  = action\n",
    "trainer.val_action  = val_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⭐[ep_0_i_35]\tloss\t0.065✨\tmae\t0.221: 100%|██████████| 38/38 [00:03<00:00, 11.48it/s]\n",
      "😎[val_ep_0_i_4]\tloss\t0.069😂\tmae\t0.216: 100%|██████████| 5/5 [00:00<00:00, 13.04it/s]\n",
      "⭐[ep_1_i_35]\tloss\t0.076✨\tmae\t0.235: 100%|██████████| 38/38 [00:03<00:00, 11.72it/s]\n",
      "😎[val_ep_1_i_4]\tloss\t0.048😂\tmae\t0.178: 100%|██████████| 5/5 [00:00<00:00, 15.16it/s]\n",
      "⭐[ep_2_i_35]\tloss\t0.058✨\tmae\t0.193: 100%|██████████| 38/38 [00:02<00:00, 13.42it/s]\n",
      "😎[val_ep_2_i_4]\tloss\t0.069😂\tmae\t0.208: 100%|██████████| 5/5 [00:00<00:00, 15.47it/s]\n",
      "⭐[ep_3_i_35]\tloss\t0.048✨\tmae\t0.160: 100%|██████████| 38/38 [00:02<00:00, 12.90it/s]\n",
      "😎[val_ep_3_i_4]\tloss\t0.037😂\tmae\t0.150: 100%|██████████| 5/5 [00:00<00:00, 14.24it/s]\n",
      "⭐[ep_4_i_35]\tloss\t0.048✨\tmae\t0.168: 100%|██████████| 38/38 [00:02<00:00, 13.37it/s]\n",
      "😎[val_ep_4_i_4]\tloss\t0.033😂\tmae\t0.146: 100%|██████████| 5/5 [00:00<00:00, 15.08it/s]\n",
      "⭐[ep_5_i_35]\tloss\t0.036✨\tmae\t0.146: 100%|██████████| 38/38 [00:02<00:00, 13.11it/s]\n",
      "😎[val_ep_5_i_4]\tloss\t0.058😂\tmae\t0.184: 100%|██████████| 5/5 [00:00<00:00, 14.00it/s]\n",
      "⭐[ep_6_i_35]\tloss\t0.097✨\tmae\t0.227: 100%|██████████| 38/38 [00:02<00:00, 12.95it/s]\n",
      "😎[val_ep_6_i_4]\tloss\t0.069😂\tmae\t0.208: 100%|██████████| 5/5 [00:00<00:00, 14.84it/s]\n",
      "⭐[ep_7_i_35]\tloss\t0.052✨\tmae\t0.201: 100%|██████████| 38/38 [00:02<00:00, 12.94it/s]\n",
      "😎[val_ep_7_i_4]\tloss\t0.047😂\tmae\t0.161: 100%|██████████| 5/5 [00:00<00:00, 14.83it/s]\n",
      "⭐[ep_8_i_35]\tloss\t0.051✨\tmae\t0.178: 100%|██████████| 38/38 [00:02<00:00, 12.93it/s]\n",
      "😎[val_ep_8_i_4]\tloss\t0.035😂\tmae\t0.160: 100%|██████████| 5/5 [00:00<00:00, 16.48it/s]\n",
      "⭐[ep_9_i_35]\tloss\t0.043✨\tmae\t0.166: 100%|██████████| 38/38 [00:02<00:00, 13.21it/s]\n",
      "😎[val_ep_9_i_4]\tloss\t0.031😂\tmae\t0.132: 100%|██████████| 5/5 [00:00<00:00, 15.45it/s]\n",
      "⭐[ep_10_i_35]\tloss\t0.038✨\tmae\t0.156: 100%|██████████| 38/38 [00:02<00:00, 13.31it/s]\n",
      "😎[val_ep_10_i_4]\tloss\t0.039😂\tmae\t0.150: 100%|██████████| 5/5 [00:00<00:00, 13.33it/s]\n",
      "⭐[ep_11_i_35]\tloss\t0.060✨\tmae\t0.199: 100%|██████████| 38/38 [00:02<00:00, 12.85it/s]\n",
      "😎[val_ep_11_i_4]\tloss\t0.036😂\tmae\t0.147: 100%|██████████| 5/5 [00:00<00:00, 15.87it/s]\n",
      "⭐[ep_12_i_35]\tloss\t0.036✨\tmae\t0.146: 100%|██████████| 38/38 [00:02<00:00, 13.91it/s]\n",
      "😎[val_ep_12_i_4]\tloss\t0.037😂\tmae\t0.145: 100%|██████████| 5/5 [00:00<00:00, 15.37it/s]\n",
      "⭐[ep_13_i_35]\tloss\t0.040✨\tmae\t0.158: 100%|██████████| 38/38 [00:02<00:00, 13.59it/s]\n",
      "😎[val_ep_13_i_4]\tloss\t0.062😂\tmae\t0.196: 100%|██████████| 5/5 [00:00<00:00, 16.58it/s]\n",
      "⭐[ep_14_i_35]\tloss\t0.037✨\tmae\t0.152: 100%|██████████| 38/38 [00:02<00:00, 12.79it/s]\n",
      "😎[val_ep_14_i_4]\tloss\t0.039😂\tmae\t0.147: 100%|██████████| 5/5 [00:00<00:00, 14.38it/s]\n",
      "⭐[ep_15_i_35]\tloss\t0.032✨\tmae\t0.144: 100%|██████████| 38/38 [00:02<00:00, 13.93it/s]\n",
      "😎[val_ep_15_i_4]\tloss\t0.049😂\tmae\t0.169: 100%|██████████| 5/5 [00:00<00:00, 16.12it/s]\n",
      "⭐[ep_16_i_35]\tloss\t0.076✨\tmae\t0.224: 100%|██████████| 38/38 [00:02<00:00, 13.69it/s]\n",
      "😎[val_ep_16_i_4]\tloss\t0.042😂\tmae\t0.159: 100%|██████████| 5/5 [00:00<00:00, 15.60it/s]\n",
      "⭐[ep_17_i_35]\tloss\t0.036✨\tmae\t0.155: 100%|██████████| 38/38 [00:02<00:00, 13.55it/s]\n",
      "😎[val_ep_17_i_4]\tloss\t0.040😂\tmae\t0.161: 100%|██████████| 5/5 [00:00<00:00, 15.66it/s]\n",
      "⭐[ep_18_i_35]\tloss\t0.032✨\tmae\t0.150: 100%|██████████| 38/38 [00:02<00:00, 13.72it/s]\n",
      "😎[val_ep_18_i_4]\tloss\t0.037😂\tmae\t0.148: 100%|██████████| 5/5 [00:00<00:00, 15.12it/s]\n",
      "⭐[ep_19_i_35]\tloss\t0.045✨\tmae\t0.162: 100%|██████████| 38/38 [00:02<00:00, 13.51it/s]\n",
      "😎[val_ep_19_i_4]\tloss\t0.042😂\tmae\t0.170: 100%|██████████| 5/5 [00:00<00:00, 15.61it/s]\n",
      "⭐[ep_20_i_35]\tloss\t0.048✨\tmae\t0.165: 100%|██████████| 38/38 [00:02<00:00, 13.20it/s]\n",
      "😎[val_ep_20_i_4]\tloss\t0.035😂\tmae\t0.143: 100%|██████████| 5/5 [00:00<00:00, 18.53it/s]\n",
      "⭐[ep_21_i_35]\tloss\t0.053✨\tmae\t0.190: 100%|██████████| 38/38 [00:02<00:00, 12.74it/s]\n",
      "😎[val_ep_21_i_4]\tloss\t0.034😂\tmae\t0.149: 100%|██████████| 5/5 [00:00<00:00, 15.70it/s]\n",
      "⭐[ep_22_i_35]\tloss\t0.061✨\tmae\t0.191: 100%|██████████| 38/38 [00:02<00:00, 13.23it/s]\n",
      "😎[val_ep_22_i_4]\tloss\t0.050😂\tmae\t0.176: 100%|██████████| 5/5 [00:00<00:00, 12.91it/s]\n",
      "⭐[ep_23_i_35]\tloss\t0.038✨\tmae\t0.169: 100%|██████████| 38/38 [00:03<00:00, 11.84it/s]\n",
      "😎[val_ep_23_i_4]\tloss\t0.044😂\tmae\t0.163: 100%|██████████| 5/5 [00:00<00:00, 13.41it/s]\n",
      "⭐[ep_24_i_35]\tloss\t0.032✨\tmae\t0.141: 100%|██████████| 38/38 [00:03<00:00, 10.52it/s]\n",
      "😎[val_ep_24_i_4]\tloss\t0.034😂\tmae\t0.151: 100%|██████████| 5/5 [00:00<00:00, 13.65it/s]\n",
      "⭐[ep_25_i_35]\tloss\t0.027✨\tmae\t0.120: 100%|██████████| 38/38 [00:03<00:00, 10.49it/s]\n",
      "😎[val_ep_25_i_4]\tloss\t0.043😂\tmae\t0.165: 100%|██████████| 5/5 [00:00<00:00, 15.35it/s]\n",
      "⭐[ep_26_i_35]\tloss\t0.040✨\tmae\t0.169: 100%|██████████| 38/38 [00:03<00:00, 11.44it/s]\n",
      "😎[val_ep_26_i_4]\tloss\t0.038😂\tmae\t0.154: 100%|██████████| 5/5 [00:00<00:00, 14.57it/s]\n",
      "⭐[ep_27_i_35]\tloss\t0.038✨\tmae\t0.155: 100%|██████████| 38/38 [00:03<00:00, 11.13it/s]\n",
      "😎[val_ep_27_i_4]\tloss\t0.050😂\tmae\t0.171: 100%|██████████| 5/5 [00:00<00:00, 13.50it/s]\n",
      "⭐[ep_28_i_35]\tloss\t0.050✨\tmae\t0.170: 100%|██████████| 38/38 [00:03<00:00, 10.70it/s]\n",
      "😎[val_ep_28_i_4]\tloss\t0.048😂\tmae\t0.166: 100%|██████████| 5/5 [00:00<00:00, 14.13it/s]\n",
      "⭐[ep_29_i_35]\tloss\t0.054✨\tmae\t0.175: 100%|██████████| 38/38 [00:03<00:00, 11.40it/s]\n",
      "😎[val_ep_29_i_4]\tloss\t0.047😂\tmae\t0.165: 100%|██████████| 5/5 [00:00<00:00, 14.46it/s]\n",
      "⭐[ep_30_i_35]\tloss\t0.059✨\tmae\t0.187: 100%|██████████| 38/38 [00:03<00:00, 10.95it/s]\n",
      "😎[val_ep_30_i_4]\tloss\t0.023😂\tmae\t0.125: 100%|██████████| 5/5 [00:00<00:00, 12.71it/s]\n",
      "⭐[ep_31_i_35]\tloss\t0.046✨\tmae\t0.180: 100%|██████████| 38/38 [00:03<00:00, 10.17it/s]\n",
      "😎[val_ep_31_i_4]\tloss\t0.035😂\tmae\t0.149: 100%|██████████| 5/5 [00:00<00:00, 13.13it/s]\n",
      "⭐[ep_32_i_35]\tloss\t0.046✨\tmae\t0.180: 100%|██████████| 38/38 [00:03<00:00, 10.97it/s]\n",
      "😎[val_ep_32_i_4]\tloss\t0.055😂\tmae\t0.180: 100%|██████████| 5/5 [00:00<00:00, 15.06it/s]\n",
      "⭐[ep_33_i_35]\tloss\t0.052✨\tmae\t0.194: 100%|██████████| 38/38 [00:03<00:00, 10.96it/s]\n",
      "😎[val_ep_33_i_4]\tloss\t0.044😂\tmae\t0.154: 100%|██████████| 5/5 [00:00<00:00, 14.37it/s]\n",
      "⭐[ep_34_i_35]\tloss\t0.067✨\tmae\t0.194: 100%|██████████| 38/38 [00:03<00:00, 11.43it/s]\n",
      "😎[val_ep_34_i_4]\tloss\t0.044😂\tmae\t0.172: 100%|██████████| 5/5 [00:00<00:00, 15.83it/s]\n",
      "⭐[ep_35_i_35]\tloss\t0.070✨\tmae\t0.206: 100%|██████████| 38/38 [00:03<00:00, 12.16it/s]\n",
      "😎[val_ep_35_i_4]\tloss\t0.044😂\tmae\t0.164: 100%|██████████| 5/5 [00:00<00:00, 15.52it/s]\n",
      "⭐[ep_36_i_35]\tloss\t0.043✨\tmae\t0.168: 100%|██████████| 38/38 [00:03<00:00, 12.64it/s]\n",
      "😎[val_ep_36_i_4]\tloss\t0.030😂\tmae\t0.142: 100%|██████████| 5/5 [00:00<00:00, 15.53it/s]\n",
      "⭐[ep_37_i_35]\tloss\t0.046✨\tmae\t0.176: 100%|██████████| 38/38 [00:03<00:00, 12.18it/s]\n",
      "😎[val_ep_37_i_4]\tloss\t0.043😂\tmae\t0.166: 100%|██████████| 5/5 [00:00<00:00, 15.50it/s]\n",
      "⭐[ep_38_i_35]\tloss\t0.043✨\tmae\t0.174: 100%|██████████| 38/38 [00:03<00:00, 12.28it/s]\n",
      "😎[val_ep_38_i_4]\tloss\t0.033😂\tmae\t0.131: 100%|██████████| 5/5 [00:00<00:00, 14.84it/s]\n",
      "⭐[ep_39_i_35]\tloss\t0.035✨\tmae\t0.152: 100%|██████████| 38/38 [00:03<00:00, 11.21it/s]\n",
      "😎[val_ep_39_i_4]\tloss\t0.049😂\tmae\t0.162: 100%|██████████| 5/5 [00:00<00:00, 15.26it/s]\n",
      "⭐[ep_40_i_35]\tloss\t0.048✨\tmae\t0.176: 100%|██████████| 38/38 [00:03<00:00, 11.54it/s]\n",
      "😎[val_ep_40_i_4]\tloss\t0.043😂\tmae\t0.171: 100%|██████████| 5/5 [00:00<00:00, 16.06it/s]\n",
      "⭐[ep_41_i_35]\tloss\t0.038✨\tmae\t0.162: 100%|██████████| 38/38 [00:03<00:00, 12.12it/s]\n",
      "😎[val_ep_41_i_4]\tloss\t0.036😂\tmae\t0.145: 100%|██████████| 5/5 [00:00<00:00, 16.10it/s]\n",
      "⭐[ep_42_i_35]\tloss\t0.034✨\tmae\t0.152: 100%|██████████| 38/38 [00:03<00:00, 11.89it/s]\n",
      "😎[val_ep_42_i_4]\tloss\t0.031😂\tmae\t0.136: 100%|██████████| 5/5 [00:00<00:00, 16.16it/s]\n",
      "⭐[ep_43_i_35]\tloss\t0.035✨\tmae\t0.154: 100%|██████████| 38/38 [00:03<00:00, 11.97it/s]\n",
      "😎[val_ep_43_i_4]\tloss\t0.067😂\tmae\t0.200: 100%|██████████| 5/5 [00:00<00:00, 16.56it/s]\n",
      "⭐[ep_44_i_35]\tloss\t0.044✨\tmae\t0.171: 100%|██████████| 38/38 [00:03<00:00, 11.54it/s]\n",
      "😎[val_ep_44_i_4]\tloss\t0.052😂\tmae\t0.187: 100%|██████████| 5/5 [00:00<00:00, 15.84it/s]\n",
      "⭐[ep_45_i_35]\tloss\t0.046✨\tmae\t0.165: 100%|██████████| 38/38 [00:03<00:00, 10.30it/s]\n",
      "😎[val_ep_45_i_4]\tloss\t0.042😂\tmae\t0.166: 100%|██████████| 5/5 [00:00<00:00, 11.65it/s]\n",
      "⭐[ep_46_i_35]\tloss\t0.041✨\tmae\t0.165: 100%|██████████| 38/38 [00:03<00:00, 11.18it/s]\n",
      "😎[val_ep_46_i_4]\tloss\t0.044😂\tmae\t0.177: 100%|██████████| 5/5 [00:00<00:00, 15.93it/s]\n",
      "⭐[ep_47_i_35]\tloss\t0.046✨\tmae\t0.177: 100%|██████████| 38/38 [00:03<00:00, 12.00it/s]\n",
      "😎[val_ep_47_i_4]\tloss\t0.032😂\tmae\t0.153: 100%|██████████| 5/5 [00:00<00:00, 15.63it/s]\n",
      "⭐[ep_48_i_35]\tloss\t0.061✨\tmae\t0.199: 100%|██████████| 38/38 [00:03<00:00, 11.86it/s]\n",
      "😎[val_ep_48_i_4]\tloss\t0.046😂\tmae\t0.168: 100%|██████████| 5/5 [00:00<00:00, 15.95it/s]\n",
      "⭐[ep_49_i_35]\tloss\t0.038✨\tmae\t0.170: 100%|██████████| 38/38 [00:03<00:00, 12.00it/s]\n",
      "😎[val_ep_49_i_4]\tloss\t0.030😂\tmae\t0.142: 100%|██████████| 5/5 [00:00<00:00, 15.60it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
